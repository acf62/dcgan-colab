{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acf62/dcgan-colab/blob/master/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNtKMXSfeHeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zPYSMRsb_XC",
        "colab_type": "text"
      },
      "source": [
        "**MinibatchDiscrimination.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZH9Ay02cDyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.init as init\n",
        "\n",
        "class MinibatchDiscrimination(nn.Module):\n",
        "    def __init__(self, in_features, out_features, kernel_dims, mean=False):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.kernel_dims = kernel_dims\n",
        "        self.mean = mean\n",
        "        self.T = nn.Parameter(torch.Tensor(in_features, out_features, kernel_dims))\n",
        "        init.normal(self.T, 0, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is NxA\n",
        "        # T is AxBxC\n",
        "        matrices = x.mm(self.T.view(self.in_features, -1))\n",
        "        matrices = matrices.view(-1, self.out_features, self.kernel_dims)\n",
        "\n",
        "        M = matrices.unsqueeze(0)  # 1xNxBxC\n",
        "        M_T = M.permute(1, 0, 2, 3)  # Nx1xBxC\n",
        "        norm = torch.abs(M - M_T).sum(3)  # NxNxB\n",
        "        expnorm = torch.exp(-norm)\n",
        "        o_b = (expnorm.sum(0) - 1)   # NxB, subtract self distance\n",
        "        if self.mean:\n",
        "            o_b /= x.size(0) - 1\n",
        "\n",
        "        x = torch.cat([x, o_b], 1)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4jEqbKKaTxD",
        "colab_type": "text"
      },
      "source": [
        "**DCGAN.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTNcy-NFrkV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "nfg = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "nfd = 64\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.optimizer = None\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, nfg * 4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(nfg * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # nn.ConvTranspose2d(nfg * 8, nfg * 4, 4, 2, 1, bias=False),\n",
        "            # nn.BatchNorm2d(nfg * 4),\n",
        "            # nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(nfg * 4, nfg * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(nfg * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(nfg * 2, nfg * 1, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(nfg * 1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(nfg * 1, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.optimizer = None\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, nfd, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(nfd, nfd * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(nfd * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(nfd * 2, nfd * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(nfd * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # nn.Conv2d(nfd * 4, nfd * 8, 4, 2, 1, bias=False),\n",
        "            # nn.BatchNorm2d(nfd * 8),\n",
        "            # nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "\n",
        "            # nn.Conv2d(nfd * 4, 1, 4, 1, 0, bias=False),\n",
        "\n",
        "            nn.Conv2d(nfd * 4, nfd // 2, 2, 2, 0, bias=False),\n",
        "            nn.Flatten(),\n",
        "            \n",
        "            MinibatchDiscrimination(128, 8, 8),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(136, 1),\n",
        "\n",
        "            nn.Linear(1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sTdHy0vazOt",
        "colab_type": "text"
      },
      "source": [
        "Training.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3VSKG0NVOzV",
        "colab_type": "text"
      },
      "source": [
        "Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNx8Lguhr-Oo",
        "colab_type": "code",
        "outputId": "80188f46-0324-4686-e110-048f55e102b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "# Number of generators\n",
        "num_generators = 3\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 12\n",
        "\n",
        "# Steps for each generator to take before moving to the next one\n",
        "gen_steps = 10\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.00005\n",
        "\n",
        "# Beta1 hyperparameter for Adam optimizers\n",
        "# beta1 = 0.5\n",
        "\n",
        "# Initialize BCELoss function\n",
        "# criterion = nn.BCELoss()\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "def initialize_weights(layer):\n",
        "    classname = layer.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(layer.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(layer.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(layer.bias.data, 0)\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "# Create latent vectors to visualize the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "\n",
        "# Create Generator list and Discriminator\n",
        "G = [Generator(ngpu=ngpu).to(device) for _ in range(num_generators)]\n",
        "D = Discriminator(ngpu=ngpu).to(device)\n",
        "\n",
        "# Initialize the network weights\n",
        "[Gi.apply(initialize_weights) for Gi in G]\n",
        "D.apply(initialize_weights)\n",
        "\n",
        "# Setup RMSProp optimizers for both G and D\n",
        "D.optimizer = optim.RMSprop(D.parameters(), lr=lr)\n",
        "for Gi in G: \n",
        "    Gi.optimizer = optim.RMSprop(Gi.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nkemb8ihVSnq",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkOWTdLiVIAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_log(iters, epoch, data_length, err_D, err_Gi, D_x, D_Gi_z1, D_Gi_z2, i):\n",
        "    # Print training statistics and save losses for plotting\n",
        "    print('[%d][%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "        % (i, epoch+1, num_epochs, iters, data_length,\n",
        "          err_D.item(), err_Gi.item(), D_x, D_Gi_z1, D_Gi_z2))\n",
        "            \n",
        "    D_losses[i].append(err_D.item())\n",
        "    G_losses[i].append(err_Gi.item())\n",
        "\n",
        "# Log an image for each generator          \n",
        "def image_log():\n",
        "    for i in range(num_generators):\n",
        "        with torch.no_grad():\n",
        "            fake = G[i](fixed_noise).detach().cpu()\n",
        "        img_list[i].append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "\n",
        "def step(Gi, data):\n",
        "    fake = None\n",
        "    for _ in range(5):\n",
        "        # Discriminator real samples\n",
        "        D.zero_grad()\n",
        "        batch = data[0].to(device)\n",
        "        output = D(batch).view(-1)\n",
        "        batch_size = batch.size(0)\n",
        "        # labels = torch.full((batch_size, ), real_label, device=device)\n",
        "        err_D_real = -torch.mean(output)\n",
        "        err_D_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # Discriminator fake samples\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        fake = Gi(noise)\n",
        "        output = D(fake.detach()).view(-1)\n",
        "        # labels.fill_(fake_label)\n",
        "        err_D_fake = torch.mean(output)\n",
        "        err_D_fake.backward()\n",
        "        err_D = err_D_real + err_D_fake\n",
        "        D_Gi_z1 = output.mean().item()\n",
        "\n",
        "        # Discriminator step\n",
        "        D.optimizer.step()\n",
        "\n",
        "        # Clamp weights for Wasserstein GAN\n",
        "        for p in D.parameters():\n",
        "            p.data.clamp_(-0.01, 0.01)\n",
        "\n",
        "    # Generator trained with improved Discriminator\n",
        "    Gi.zero_grad()\n",
        "    # labels.fill_(real_label)\n",
        "    output = D(fake).view(-1)\n",
        "    err_Gi = -torch.mean(output)\n",
        "    err_Gi.backward()\n",
        "    D_Gi_z2 = output.mean().item()\n",
        "   \n",
        "    # Generator step\n",
        "    Gi.optimizer.step()\n",
        "\n",
        "    return err_D, err_Gi, D_x, D_Gi_z1, D_Gi_z2\n",
        "\n",
        "\n",
        "def train(data_loader):\n",
        "    for epoch in range(num_epochs):\n",
        "        iters = 0\n",
        "        i = epoch % num_generators\n",
        "        for data in data_loader:\n",
        "            # Optimization Step\n",
        "            Gi = G[i]\n",
        "            err_D, err_Gi, D_x, D_Gi_z1, D_Gi_z2 = step(Gi, data)\n",
        "            \n",
        "            if (iters + 1) % gen_steps == 0:\n",
        "                # Log for plotting\n",
        "                data_log(iters, epoch, len(data_loader), err_D, err_Gi, D_x, D_Gi_z1, D_Gi_z2, i)\n",
        "                # Train next generator  \n",
        "                i = (i + 1) % num_generators\n",
        "            iters += 1\n",
        "        image_log()           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyIXZNuVa2QR",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WntOuuaGsbTg",
        "colab_type": "code",
        "outputId": "12d0e47c-ad75-4283-b9b5-780bda06862f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.utils.data\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "# Root directory for dataset\n",
        "dataroot = \"data\"\n",
        "\n",
        "# Number of workers for data_loader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
        "image_size = 32\n",
        "\n",
        "\n",
        "# We can use an image folder dataset the way we have it setup.\n",
        "# Create the dataset\n",
        "dataset = dsets.CIFAR10(root=dataroot, train=True, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5,))\n",
        "                           ]))\n",
        "\n",
        "\n",
        "# Create the data_loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers, drop_last=True)\n",
        "\n",
        "# Lists to hold the data for plotting\n",
        "img_list = [[] for _ in range(num_generators)]\n",
        "G_losses = [[] for _ in range(num_generators)]\n",
        "D_losses = [[] for _ in range(num_generators)]\n",
        "display = 0\n",
        "\n",
        "# Train the GAN\n",
        "train(data_loader)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "[0][1/12][9/390]\tLoss_D: -0.0003\tLoss_G: 0.0512\tD(x): -0.0509\tD(G(z)): -0.0512 / -0.0512\n",
            "[1][1/12][19/390]\tLoss_D: -0.0014\tLoss_G: 0.0532\tD(x): -0.0514\tD(G(z)): -0.0528 / -0.0532\n",
            "[2][1/12][29/390]\tLoss_D: -0.0056\tLoss_G: 0.0643\tD(x): -0.0591\tD(G(z)): -0.0647 / -0.0643\n",
            "[0][1/12][39/390]\tLoss_D: -0.0081\tLoss_G: 0.0688\tD(x): -0.0604\tD(G(z)): -0.0686 / -0.0688\n",
            "[1][1/12][49/390]\tLoss_D: -0.0105\tLoss_G: 0.0905\tD(x): -0.0803\tD(G(z)): -0.0909 / -0.0905\n",
            "[2][1/12][59/390]\tLoss_D: -0.0193\tLoss_G: 0.1023\tD(x): -0.0831\tD(G(z)): -0.1024 / -0.1023\n",
            "[0][1/12][69/390]\tLoss_D: -0.0225\tLoss_G: 0.1027\tD(x): -0.0827\tD(G(z)): -0.1052 / -0.1027\n",
            "[1][1/12][79/390]\tLoss_D: -0.0180\tLoss_G: 0.0979\tD(x): -0.0856\tD(G(z)): -0.1036 / -0.0979\n",
            "[2][1/12][89/390]\tLoss_D: -0.0253\tLoss_G: 0.0997\tD(x): -0.0775\tD(G(z)): -0.1028 / -0.0997\n",
            "[0][1/12][99/390]\tLoss_D: -0.0278\tLoss_G: 0.1009\tD(x): -0.0770\tD(G(z)): -0.1048 / -0.1009\n",
            "[1][1/12][109/390]\tLoss_D: -0.0230\tLoss_G: 0.1013\tD(x): -0.0752\tD(G(z)): -0.0982 / -0.1013\n",
            "[2][1/12][119/390]\tLoss_D: -0.0261\tLoss_G: 0.0994\tD(x): -0.0699\tD(G(z)): -0.0960 / -0.0994\n",
            "[0][1/12][129/390]\tLoss_D: -0.0343\tLoss_G: 0.1012\tD(x): -0.0716\tD(G(z)): -0.1060 / -0.1012\n",
            "[1][1/12][139/390]\tLoss_D: -0.0243\tLoss_G: 0.0941\tD(x): -0.0773\tD(G(z)): -0.1016 / -0.0941\n",
            "[2][1/12][149/390]\tLoss_D: -0.0335\tLoss_G: 0.1062\tD(x): -0.0731\tD(G(z)): -0.1066 / -0.1062\n",
            "[0][1/12][159/390]\tLoss_D: -0.0383\tLoss_G: 0.1026\tD(x): -0.0677\tD(G(z)): -0.1060 / -0.1026\n",
            "[1][1/12][169/390]\tLoss_D: -0.0212\tLoss_G: 0.1026\tD(x): -0.0746\tD(G(z)): -0.0959 / -0.1026\n",
            "[2][1/12][179/390]\tLoss_D: -0.0366\tLoss_G: 0.1002\tD(x): -0.0696\tD(G(z)): -0.1061 / -0.1002\n",
            "[0][1/12][189/390]\tLoss_D: -0.0422\tLoss_G: 0.1050\tD(x): -0.0648\tD(G(z)): -0.1069 / -0.1050\n",
            "[1][1/12][199/390]\tLoss_D: -0.0350\tLoss_G: 0.0999\tD(x): -0.0709\tD(G(z)): -0.1058 / -0.0999\n",
            "[2][1/12][209/390]\tLoss_D: -0.0397\tLoss_G: 0.1069\tD(x): -0.0643\tD(G(z)): -0.1040 / -0.1069\n",
            "[0][1/12][219/390]\tLoss_D: -0.0419\tLoss_G: 0.1048\tD(x): -0.0663\tD(G(z)): -0.1082 / -0.1048\n",
            "[1][1/12][229/390]\tLoss_D: -0.0345\tLoss_G: 0.1052\tD(x): -0.0668\tD(G(z)): -0.1013 / -0.1052\n",
            "[2][1/12][239/390]\tLoss_D: -0.0425\tLoss_G: 0.1079\tD(x): -0.0648\tD(G(z)): -0.1074 / -0.1079\n",
            "[0][1/12][249/390]\tLoss_D: -0.0435\tLoss_G: 0.1074\tD(x): -0.0651\tD(G(z)): -0.1087 / -0.1074\n",
            "[1][1/12][259/390]\tLoss_D: -0.0370\tLoss_G: 0.1008\tD(x): -0.0668\tD(G(z)): -0.1038 / -0.1008\n",
            "[2][1/12][269/390]\tLoss_D: -0.0442\tLoss_G: 0.1065\tD(x): -0.0637\tD(G(z)): -0.1079 / -0.1065\n",
            "[0][1/12][279/390]\tLoss_D: -0.0440\tLoss_G: 0.1071\tD(x): -0.0645\tD(G(z)): -0.1085 / -0.1071\n",
            "[1][1/12][289/390]\tLoss_D: -0.0407\tLoss_G: 0.1061\tD(x): -0.0660\tD(G(z)): -0.1067 / -0.1061\n",
            "[2][1/12][299/390]\tLoss_D: -0.0420\tLoss_G: 0.1064\tD(x): -0.0659\tD(G(z)): -0.1079 / -0.1064\n",
            "[0][1/12][309/390]\tLoss_D: -0.0460\tLoss_G: 0.1085\tD(x): -0.0616\tD(G(z)): -0.1076 / -0.1085\n",
            "[1][1/12][319/390]\tLoss_D: -0.0419\tLoss_G: 0.1071\tD(x): -0.0637\tD(G(z)): -0.1056 / -0.1071\n",
            "[2][1/12][329/390]\tLoss_D: -0.0443\tLoss_G: 0.1070\tD(x): -0.0638\tD(G(z)): -0.1082 / -0.1070\n",
            "[0][1/12][339/390]\tLoss_D: -0.0442\tLoss_G: 0.1084\tD(x): -0.0627\tD(G(z)): -0.1068 / -0.1084\n",
            "[1][1/12][349/390]\tLoss_D: -0.0419\tLoss_G: 0.1080\tD(x): -0.0625\tD(G(z)): -0.1044 / -0.1080\n",
            "[2][1/12][359/390]\tLoss_D: -0.0439\tLoss_G: 0.1073\tD(x): -0.0640\tD(G(z)): -0.1080 / -0.1073\n",
            "[0][1/12][369/390]\tLoss_D: -0.0453\tLoss_G: 0.1082\tD(x): -0.0614\tD(G(z)): -0.1067 / -0.1082\n",
            "[1][1/12][379/390]\tLoss_D: -0.0448\tLoss_G: 0.1057\tD(x): -0.0620\tD(G(z)): -0.1068 / -0.1057\n",
            "[2][1/12][389/390]\tLoss_D: -0.0465\tLoss_G: 0.1070\tD(x): -0.0617\tD(G(z)): -0.1082 / -0.1070\n",
            "[1][2/12][9/390]\tLoss_D: -0.0464\tLoss_G: 0.1068\tD(x): -0.0605\tD(G(z)): -0.1069 / -0.1068\n",
            "[2][2/12][19/390]\tLoss_D: -0.0437\tLoss_G: 0.1060\tD(x): -0.0643\tD(G(z)): -0.1080 / -0.1060\n",
            "[0][2/12][29/390]\tLoss_D: -0.0475\tLoss_G: 0.1085\tD(x): -0.0604\tD(G(z)): -0.1079 / -0.1085\n",
            "[1][2/12][39/390]\tLoss_D: -0.0434\tLoss_G: 0.1050\tD(x): -0.0619\tD(G(z)): -0.1053 / -0.1050\n",
            "[2][2/12][49/390]\tLoss_D: -0.0451\tLoss_G: 0.1070\tD(x): -0.0624\tD(G(z)): -0.1075 / -0.1070\n",
            "[0][2/12][59/390]\tLoss_D: -0.0459\tLoss_G: 0.1073\tD(x): -0.0620\tD(G(z)): -0.1079 / -0.1073\n",
            "[1][2/12][69/390]\tLoss_D: -0.0443\tLoss_G: 0.1068\tD(x): -0.0607\tD(G(z)): -0.1050 / -0.1068\n",
            "[2][2/12][79/390]\tLoss_D: -0.0476\tLoss_G: 0.1070\tD(x): -0.0604\tD(G(z)): -0.1080 / -0.1070\n",
            "[0][2/12][89/390]\tLoss_D: -0.0466\tLoss_G: 0.1077\tD(x): -0.0606\tD(G(z)): -0.1072 / -0.1077\n",
            "[1][2/12][99/390]\tLoss_D: -0.0435\tLoss_G: 0.1034\tD(x): -0.0618\tD(G(z)): -0.1053 / -0.1034\n",
            "[2][2/12][109/390]\tLoss_D: -0.0468\tLoss_G: 0.1071\tD(x): -0.0607\tD(G(z)): -0.1075 / -0.1071\n",
            "[0][2/12][119/390]\tLoss_D: -0.0454\tLoss_G: 0.1073\tD(x): -0.0624\tD(G(z)): -0.1078 / -0.1073\n",
            "[1][2/12][129/390]\tLoss_D: -0.0470\tLoss_G: 0.1049\tD(x): -0.0596\tD(G(z)): -0.1066 / -0.1049\n",
            "[2][2/12][139/390]\tLoss_D: -0.0464\tLoss_G: 0.1074\tD(x): -0.0618\tD(G(z)): -0.1082 / -0.1074\n",
            "[0][2/12][149/390]\tLoss_D: -0.0477\tLoss_G: 0.1083\tD(x): -0.0592\tD(G(z)): -0.1070 / -0.1083\n",
            "[1][2/12][159/390]\tLoss_D: -0.0474\tLoss_G: 0.1058\tD(x): -0.0605\tD(G(z)): -0.1079 / -0.1058\n",
            "[2][2/12][169/390]\tLoss_D: -0.0458\tLoss_G: 0.1070\tD(x): -0.0624\tD(G(z)): -0.1082 / -0.1070\n",
            "[0][2/12][179/390]\tLoss_D: -0.0480\tLoss_G: 0.1083\tD(x): -0.0592\tD(G(z)): -0.1071 / -0.1083\n",
            "[1][2/12][189/390]\tLoss_D: -0.0459\tLoss_G: 0.1045\tD(x): -0.0607\tD(G(z)): -0.1066 / -0.1045\n",
            "[2][2/12][199/390]\tLoss_D: -0.0468\tLoss_G: 0.1072\tD(x): -0.0614\tD(G(z)): -0.1082 / -0.1072\n",
            "[0][2/12][209/390]\tLoss_D: -0.0479\tLoss_G: 0.1084\tD(x): -0.0601\tD(G(z)): -0.1080 / -0.1084\n",
            "[1][2/12][219/390]\tLoss_D: -0.0424\tLoss_G: 0.1081\tD(x): -0.0607\tD(G(z)): -0.1030 / -0.1081\n",
            "[2][2/12][229/390]\tLoss_D: -0.0458\tLoss_G: 0.1079\tD(x): -0.0625\tD(G(z)): -0.1083 / -0.1079\n",
            "[0][2/12][239/390]\tLoss_D: -0.0483\tLoss_G: 0.1077\tD(x): -0.0599\tD(G(z)): -0.1082 / -0.1077\n",
            "[1][2/12][249/390]\tLoss_D: -0.0493\tLoss_G: 0.1065\tD(x): -0.0597\tD(G(z)): -0.1090 / -0.1065\n",
            "[2][2/12][259/390]\tLoss_D: -0.0478\tLoss_G: 0.1078\tD(x): -0.0601\tD(G(z)): -0.1079 / -0.1078\n",
            "[0][2/12][269/390]\tLoss_D: -0.0458\tLoss_G: 0.1067\tD(x): -0.0604\tD(G(z)): -0.1062 / -0.1067\n",
            "[1][2/12][279/390]\tLoss_D: -0.0443\tLoss_G: 0.1056\tD(x): -0.0614\tD(G(z)): -0.1057 / -0.1056\n",
            "[2][2/12][289/390]\tLoss_D: -0.0493\tLoss_G: 0.1069\tD(x): -0.0587\tD(G(z)): -0.1079 / -0.1069\n",
            "[0][2/12][299/390]\tLoss_D: -0.0471\tLoss_G: 0.1077\tD(x): -0.0594\tD(G(z)): -0.1065 / -0.1077\n",
            "[1][2/12][309/390]\tLoss_D: -0.0443\tLoss_G: 0.1085\tD(x): -0.0590\tD(G(z)): -0.1033 / -0.1085\n",
            "[2][2/12][319/390]\tLoss_D: -0.0487\tLoss_G: 0.1078\tD(x): -0.0589\tD(G(z)): -0.1076 / -0.1078\n",
            "[0][2/12][329/390]\tLoss_D: -0.0463\tLoss_G: 0.1047\tD(x): -0.0604\tD(G(z)): -0.1066 / -0.1047\n",
            "[1][2/12][339/390]\tLoss_D: -0.0453\tLoss_G: 0.1067\tD(x): -0.0592\tD(G(z)): -0.1045 / -0.1067\n",
            "[2][2/12][349/390]\tLoss_D: -0.0487\tLoss_G: 0.1070\tD(x): -0.0579\tD(G(z)): -0.1066 / -0.1070\n",
            "[0][2/12][359/390]\tLoss_D: -0.0444\tLoss_G: 0.1083\tD(x): -0.0602\tD(G(z)): -0.1046 / -0.1083\n",
            "[1][2/12][369/390]\tLoss_D: -0.0459\tLoss_G: 0.1049\tD(x): -0.0601\tD(G(z)): -0.1060 / -0.1049\n",
            "[2][2/12][379/390]\tLoss_D: -0.0475\tLoss_G: 0.1077\tD(x): -0.0600\tD(G(z)): -0.1075 / -0.1077\n",
            "[0][2/12][389/390]\tLoss_D: -0.0464\tLoss_G: 0.1060\tD(x): -0.0596\tD(G(z)): -0.1060 / -0.1060\n",
            "[2][3/12][9/390]\tLoss_D: -0.0486\tLoss_G: 0.1069\tD(x): -0.0596\tD(G(z)): -0.1082 / -0.1069\n",
            "[0][3/12][19/390]\tLoss_D: -0.0463\tLoss_G: 0.1082\tD(x): -0.0595\tD(G(z)): -0.1058 / -0.1082\n",
            "[1][3/12][29/390]\tLoss_D: -0.0444\tLoss_G: 0.1072\tD(x): -0.0598\tD(G(z)): -0.1042 / -0.1072\n",
            "[2][3/12][39/390]\tLoss_D: -0.0482\tLoss_G: 0.1072\tD(x): -0.0590\tD(G(z)): -0.1072 / -0.1072\n",
            "[0][3/12][49/390]\tLoss_D: -0.0483\tLoss_G: 0.1065\tD(x): -0.0606\tD(G(z)): -0.1089 / -0.1065\n",
            "[1][3/12][59/390]\tLoss_D: -0.0447\tLoss_G: 0.1056\tD(x): -0.0610\tD(G(z)): -0.1056 / -0.1056\n",
            "[2][3/12][69/390]\tLoss_D: -0.0468\tLoss_G: 0.1082\tD(x): -0.0599\tD(G(z)): -0.1068 / -0.1082\n",
            "[0][3/12][79/390]\tLoss_D: -0.0467\tLoss_G: 0.1086\tD(x): -0.0600\tD(G(z)): -0.1067 / -0.1086\n",
            "[1][3/12][89/390]\tLoss_D: -0.0453\tLoss_G: 0.1062\tD(x): -0.0600\tD(G(z)): -0.1053 / -0.1062\n",
            "[2][3/12][99/390]\tLoss_D: -0.0476\tLoss_G: 0.1073\tD(x): -0.0595\tD(G(z)): -0.1071 / -0.1073\n",
            "[0][3/12][109/390]\tLoss_D: -0.0467\tLoss_G: 0.1080\tD(x): -0.0589\tD(G(z)): -0.1056 / -0.1080\n",
            "[1][3/12][119/390]\tLoss_D: -0.0468\tLoss_G: 0.1057\tD(x): -0.0599\tD(G(z)): -0.1067 / -0.1057\n",
            "[2][3/12][129/390]\tLoss_D: -0.0424\tLoss_G: 0.1074\tD(x): -0.0614\tD(G(z)): -0.1037 / -0.1074\n",
            "[0][3/12][139/390]\tLoss_D: -0.0475\tLoss_G: 0.1069\tD(x): -0.0592\tD(G(z)): -0.1066 / -0.1069\n",
            "[1][3/12][149/390]\tLoss_D: -0.0464\tLoss_G: 0.1050\tD(x): -0.0609\tD(G(z)): -0.1074 / -0.1050\n",
            "[2][3/12][159/390]\tLoss_D: -0.0437\tLoss_G: 0.1063\tD(x): -0.0604\tD(G(z)): -0.1041 / -0.1063\n",
            "[0][3/12][169/390]\tLoss_D: -0.0473\tLoss_G: 0.1066\tD(x): -0.0595\tD(G(z)): -0.1067 / -0.1066\n",
            "[1][3/12][179/390]\tLoss_D: -0.0462\tLoss_G: 0.1061\tD(x): -0.0595\tD(G(z)): -0.1057 / -0.1061\n",
            "[2][3/12][189/390]\tLoss_D: -0.0447\tLoss_G: 0.1049\tD(x): -0.0605\tD(G(z)): -0.1052 / -0.1049\n",
            "[0][3/12][199/390]\tLoss_D: -0.0461\tLoss_G: 0.1070\tD(x): -0.0609\tD(G(z)): -0.1070 / -0.1070\n",
            "[1][3/12][209/390]\tLoss_D: -0.0460\tLoss_G: 0.1067\tD(x): -0.0595\tD(G(z)): -0.1056 / -0.1067\n",
            "[2][3/12][219/390]\tLoss_D: -0.0463\tLoss_G: 0.1058\tD(x): -0.0593\tD(G(z)): -0.1056 / -0.1058\n",
            "[0][3/12][229/390]\tLoss_D: -0.0472\tLoss_G: 0.1071\tD(x): -0.0584\tD(G(z)): -0.1056 / -0.1071\n",
            "[1][3/12][239/390]\tLoss_D: -0.0469\tLoss_G: 0.1057\tD(x): -0.0599\tD(G(z)): -0.1068 / -0.1057\n",
            "[2][3/12][249/390]\tLoss_D: -0.0437\tLoss_G: 0.1066\tD(x): -0.0604\tD(G(z)): -0.1041 / -0.1066\n",
            "[0][3/12][259/390]\tLoss_D: -0.0453\tLoss_G: 0.1037\tD(x): -0.0607\tD(G(z)): -0.1060 / -0.1037\n",
            "[1][3/12][269/390]\tLoss_D: -0.0456\tLoss_G: 0.1062\tD(x): -0.0598\tD(G(z)): -0.1054 / -0.1062\n",
            "[2][3/12][279/390]\tLoss_D: -0.0448\tLoss_G: 0.1054\tD(x): -0.0610\tD(G(z)): -0.1058 / -0.1054\n",
            "[0][3/12][289/390]\tLoss_D: -0.0436\tLoss_G: 0.1069\tD(x): -0.0607\tD(G(z)): -0.1042 / -0.1069\n",
            "[1][3/12][299/390]\tLoss_D: -0.0475\tLoss_G: 0.1058\tD(x): -0.0586\tD(G(z)): -0.1060 / -0.1058\n",
            "[2][3/12][309/390]\tLoss_D: -0.0456\tLoss_G: 0.1058\tD(x): -0.0593\tD(G(z)): -0.1050 / -0.1058\n",
            "[0][3/12][319/390]\tLoss_D: -0.0503\tLoss_G: 0.1060\tD(x): -0.0592\tD(G(z)): -0.1095 / -0.1060\n",
            "[1][3/12][329/390]\tLoss_D: -0.0445\tLoss_G: 0.1065\tD(x): -0.0599\tD(G(z)): -0.1044 / -0.1065\n",
            "[2][3/12][339/390]\tLoss_D: -0.0472\tLoss_G: 0.1062\tD(x): -0.0582\tD(G(z)): -0.1054 / -0.1062\n",
            "[0][3/12][349/390]\tLoss_D: -0.0436\tLoss_G: 0.1092\tD(x): -0.0601\tD(G(z)): -0.1037 / -0.1092\n",
            "[1][3/12][359/390]\tLoss_D: -0.0481\tLoss_G: 0.1047\tD(x): -0.0596\tD(G(z)): -0.1077 / -0.1047\n",
            "[2][3/12][369/390]\tLoss_D: -0.0466\tLoss_G: 0.1063\tD(x): -0.0591\tD(G(z)): -0.1057 / -0.1063\n",
            "[0][3/12][379/390]\tLoss_D: -0.0458\tLoss_G: 0.1076\tD(x): -0.0589\tD(G(z)): -0.1048 / -0.1076\n",
            "[1][3/12][389/390]\tLoss_D: -0.0456\tLoss_G: 0.1056\tD(x): -0.0608\tD(G(z)): -0.1064 / -0.1056\n",
            "[0][4/12][9/390]\tLoss_D: -0.0464\tLoss_G: 0.1067\tD(x): -0.0604\tD(G(z)): -0.1067 / -0.1067\n",
            "[1][4/12][19/390]\tLoss_D: -0.0453\tLoss_G: 0.1070\tD(x): -0.0615\tD(G(z)): -0.1067 / -0.1070\n",
            "[2][4/12][29/390]\tLoss_D: -0.0459\tLoss_G: 0.1050\tD(x): -0.0603\tD(G(z)): -0.1062 / -0.1050\n",
            "[0][4/12][39/390]\tLoss_D: -0.0454\tLoss_G: 0.1094\tD(x): -0.0598\tD(G(z)): -0.1052 / -0.1094\n",
            "[1][4/12][49/390]\tLoss_D: -0.0461\tLoss_G: 0.1088\tD(x): -0.0596\tD(G(z)): -0.1057 / -0.1088\n",
            "[2][4/12][59/390]\tLoss_D: -0.0467\tLoss_G: 0.1064\tD(x): -0.0591\tD(G(z)): -0.1058 / -0.1064\n",
            "[0][4/12][69/390]\tLoss_D: -0.0451\tLoss_G: 0.1068\tD(x): -0.0593\tD(G(z)): -0.1044 / -0.1068\n",
            "[1][4/12][79/390]\tLoss_D: -0.0470\tLoss_G: 0.1066\tD(x): -0.0590\tD(G(z)): -0.1060 / -0.1066\n",
            "[2][4/12][89/390]\tLoss_D: -0.0461\tLoss_G: 0.1068\tD(x): -0.0596\tD(G(z)): -0.1057 / -0.1068\n",
            "[0][4/12][99/390]\tLoss_D: -0.0453\tLoss_G: 0.1073\tD(x): -0.0606\tD(G(z)): -0.1058 / -0.1073\n",
            "[1][4/12][109/390]\tLoss_D: -0.0460\tLoss_G: 0.1075\tD(x): -0.0591\tD(G(z)): -0.1052 / -0.1075\n",
            "[2][4/12][119/390]\tLoss_D: -0.0471\tLoss_G: 0.1064\tD(x): -0.0600\tD(G(z)): -0.1071 / -0.1064\n",
            "[0][4/12][129/390]\tLoss_D: -0.0466\tLoss_G: 0.1071\tD(x): -0.0590\tD(G(z)): -0.1056 / -0.1071\n",
            "[1][4/12][139/390]\tLoss_D: -0.0485\tLoss_G: 0.1061\tD(x): -0.0585\tD(G(z)): -0.1070 / -0.1061\n",
            "[2][4/12][149/390]\tLoss_D: -0.0475\tLoss_G: 0.1055\tD(x): -0.0603\tD(G(z)): -0.1078 / -0.1055\n",
            "[0][4/12][159/390]\tLoss_D: -0.0443\tLoss_G: 0.1075\tD(x): -0.0604\tD(G(z)): -0.1047 / -0.1075\n",
            "[1][4/12][169/390]\tLoss_D: -0.0479\tLoss_G: 0.1056\tD(x): -0.0595\tD(G(z)): -0.1074 / -0.1056\n",
            "[2][4/12][179/390]\tLoss_D: -0.0467\tLoss_G: 0.1059\tD(x): -0.0596\tD(G(z)): -0.1062 / -0.1059\n",
            "[0][4/12][189/390]\tLoss_D: -0.0456\tLoss_G: 0.1077\tD(x): -0.0593\tD(G(z)): -0.1050 / -0.1077\n",
            "[1][4/12][199/390]\tLoss_D: -0.0459\tLoss_G: 0.1069\tD(x): -0.0603\tD(G(z)): -0.1063 / -0.1069\n",
            "[2][4/12][209/390]\tLoss_D: -0.0439\tLoss_G: 0.1056\tD(x): -0.0624\tD(G(z)): -0.1063 / -0.1056\n",
            "[0][4/12][219/390]\tLoss_D: -0.0463\tLoss_G: 0.1060\tD(x): -0.0595\tD(G(z)): -0.1057 / -0.1060\n",
            "[1][4/12][229/390]\tLoss_D: -0.0460\tLoss_G: 0.1066\tD(x): -0.0605\tD(G(z)): -0.1065 / -0.1066\n",
            "[2][4/12][239/390]\tLoss_D: -0.0448\tLoss_G: 0.1055\tD(x): -0.0612\tD(G(z)): -0.1060 / -0.1055\n",
            "[0][4/12][249/390]\tLoss_D: -0.0465\tLoss_G: 0.1058\tD(x): -0.0595\tD(G(z)): -0.1061 / -0.1058\n",
            "[1][4/12][259/390]\tLoss_D: -0.0468\tLoss_G: 0.1078\tD(x): -0.0592\tD(G(z)): -0.1060 / -0.1078\n",
            "[2][4/12][269/390]\tLoss_D: -0.0466\tLoss_G: 0.1057\tD(x): -0.0601\tD(G(z)): -0.1067 / -0.1057\n",
            "[0][4/12][279/390]\tLoss_D: -0.0478\tLoss_G: 0.1063\tD(x): -0.0602\tD(G(z)): -0.1079 / -0.1063\n",
            "[1][4/12][289/390]\tLoss_D: -0.0469\tLoss_G: 0.1070\tD(x): -0.0599\tD(G(z)): -0.1067 / -0.1070\n",
            "[2][4/12][299/390]\tLoss_D: -0.0469\tLoss_G: 0.1055\tD(x): -0.0594\tD(G(z)): -0.1063 / -0.1055\n",
            "[0][4/12][309/390]\tLoss_D: -0.0457\tLoss_G: 0.1069\tD(x): -0.0601\tD(G(z)): -0.1058 / -0.1069\n",
            "[1][4/12][319/390]\tLoss_D: -0.0481\tLoss_G: 0.1069\tD(x): -0.0583\tD(G(z)): -0.1063 / -0.1069\n",
            "[2][4/12][329/390]\tLoss_D: -0.0446\tLoss_G: 0.1062\tD(x): -0.0607\tD(G(z)): -0.1053 / -0.1062\n",
            "[0][4/12][339/390]\tLoss_D: -0.0451\tLoss_G: 0.1065\tD(x): -0.0604\tD(G(z)): -0.1054 / -0.1065\n",
            "[1][4/12][349/390]\tLoss_D: -0.0478\tLoss_G: 0.1074\tD(x): -0.0594\tD(G(z)): -0.1072 / -0.1074\n",
            "[2][4/12][359/390]\tLoss_D: -0.0450\tLoss_G: 0.1050\tD(x): -0.0604\tD(G(z)): -0.1054 / -0.1050\n",
            "[0][4/12][369/390]\tLoss_D: -0.0440\tLoss_G: 0.1058\tD(x): -0.0617\tD(G(z)): -0.1057 / -0.1058\n",
            "[1][4/12][379/390]\tLoss_D: -0.0465\tLoss_G: 0.1067\tD(x): -0.0604\tD(G(z)): -0.1069 / -0.1067\n",
            "[2][4/12][389/390]\tLoss_D: -0.0465\tLoss_G: 0.1051\tD(x): -0.0596\tD(G(z)): -0.1061 / -0.1051\n",
            "[1][5/12][9/390]\tLoss_D: -0.0455\tLoss_G: 0.1079\tD(x): -0.0603\tD(G(z)): -0.1058 / -0.1079\n",
            "[2][5/12][19/390]\tLoss_D: -0.0449\tLoss_G: 0.1062\tD(x): -0.0601\tD(G(z)): -0.1049 / -0.1062\n",
            "[0][5/12][29/390]\tLoss_D: -0.0458\tLoss_G: 0.1050\tD(x): -0.0629\tD(G(z)): -0.1087 / -0.1050\n",
            "[1][5/12][39/390]\tLoss_D: -0.0468\tLoss_G: 0.1071\tD(x): -0.0592\tD(G(z)): -0.1060 / -0.1071\n",
            "[2][5/12][49/390]\tLoss_D: -0.0447\tLoss_G: 0.1036\tD(x): -0.0608\tD(G(z)): -0.1056 / -0.1036\n",
            "[0][5/12][59/390]\tLoss_D: -0.0401\tLoss_G: 0.1052\tD(x): -0.0620\tD(G(z)): -0.1021 / -0.1052\n",
            "[1][5/12][69/390]\tLoss_D: -0.0474\tLoss_G: 0.1062\tD(x): -0.0592\tD(G(z)): -0.1066 / -0.1062\n",
            "[2][5/12][79/390]\tLoss_D: -0.0444\tLoss_G: 0.1036\tD(x): -0.0612\tD(G(z)): -0.1055 / -0.1036\n",
            "[0][5/12][89/390]\tLoss_D: -0.0451\tLoss_G: 0.1017\tD(x): -0.0614\tD(G(z)): -0.1065 / -0.1017\n",
            "[1][5/12][99/390]\tLoss_D: -0.0469\tLoss_G: 0.1076\tD(x): -0.0593\tD(G(z)): -0.1062 / -0.1076\n",
            "[2][5/12][109/390]\tLoss_D: -0.0429\tLoss_G: 0.1046\tD(x): -0.0619\tD(G(z)): -0.1048 / -0.1046\n",
            "[0][5/12][119/390]\tLoss_D: -0.0441\tLoss_G: 0.1067\tD(x): -0.0608\tD(G(z)): -0.1049 / -0.1067\n",
            "[1][5/12][129/390]\tLoss_D: -0.0487\tLoss_G: 0.1065\tD(x): -0.0583\tD(G(z)): -0.1070 / -0.1065\n",
            "[2][5/12][139/390]\tLoss_D: -0.0445\tLoss_G: 0.1051\tD(x): -0.0603\tD(G(z)): -0.1049 / -0.1051\n",
            "[0][5/12][149/390]\tLoss_D: -0.0476\tLoss_G: 0.1049\tD(x): -0.0600\tD(G(z)): -0.1076 / -0.1049\n",
            "[1][5/12][159/390]\tLoss_D: -0.0465\tLoss_G: 0.1069\tD(x): -0.0597\tD(G(z)): -0.1062 / -0.1069\n",
            "[2][5/12][169/390]\tLoss_D: -0.0418\tLoss_G: 0.1066\tD(x): -0.0615\tD(G(z)): -0.1033 / -0.1066\n",
            "[0][5/12][179/390]\tLoss_D: -0.0435\tLoss_G: 0.1024\tD(x): -0.0608\tD(G(z)): -0.1043 / -0.1024\n",
            "[1][5/12][189/390]\tLoss_D: -0.0464\tLoss_G: 0.1072\tD(x): -0.0599\tD(G(z)): -0.1063 / -0.1072\n",
            "[2][5/12][199/390]\tLoss_D: -0.0422\tLoss_G: 0.1017\tD(x): -0.0627\tD(G(z)): -0.1049 / -0.1017\n",
            "[0][5/12][209/390]\tLoss_D: -0.0433\tLoss_G: 0.1039\tD(x): -0.0607\tD(G(z)): -0.1040 / -0.1039\n",
            "[1][5/12][219/390]\tLoss_D: -0.0465\tLoss_G: 0.1064\tD(x): -0.0606\tD(G(z)): -0.1071 / -0.1064\n",
            "[2][5/12][229/390]\tLoss_D: -0.0422\tLoss_G: 0.1047\tD(x): -0.0606\tD(G(z)): -0.1028 / -0.1047\n",
            "[0][5/12][239/390]\tLoss_D: -0.0422\tLoss_G: 0.1046\tD(x): -0.0612\tD(G(z)): -0.1034 / -0.1046\n",
            "[1][5/12][249/390]\tLoss_D: -0.0455\tLoss_G: 0.1079\tD(x): -0.0601\tD(G(z)): -0.1056 / -0.1079\n",
            "[2][5/12][259/390]\tLoss_D: -0.0429\tLoss_G: 0.1038\tD(x): -0.0615\tD(G(z)): -0.1044 / -0.1038\n",
            "[0][5/12][269/390]\tLoss_D: -0.0409\tLoss_G: 0.1058\tD(x): -0.0612\tD(G(z)): -0.1021 / -0.1058\n",
            "[1][5/12][279/390]\tLoss_D: -0.0451\tLoss_G: 0.1081\tD(x): -0.0608\tD(G(z)): -0.1058 / -0.1081\n",
            "[2][5/12][289/390]\tLoss_D: -0.0415\tLoss_G: 0.1058\tD(x): -0.0617\tD(G(z)): -0.1032 / -0.1058\n",
            "[0][5/12][299/390]\tLoss_D: -0.0466\tLoss_G: 0.1008\tD(x): -0.0608\tD(G(z)): -0.1073 / -0.1008\n",
            "[1][5/12][309/390]\tLoss_D: -0.0470\tLoss_G: 0.1079\tD(x): -0.0587\tD(G(z)): -0.1057 / -0.1079\n",
            "[2][5/12][319/390]\tLoss_D: -0.0432\tLoss_G: 0.1044\tD(x): -0.0621\tD(G(z)): -0.1053 / -0.1044\n",
            "[0][5/12][329/390]\tLoss_D: -0.0406\tLoss_G: 0.1064\tD(x): -0.0617\tD(G(z)): -0.1022 / -0.1064\n",
            "[1][5/12][339/390]\tLoss_D: -0.0461\tLoss_G: 0.1065\tD(x): -0.0597\tD(G(z)): -0.1058 / -0.1065\n",
            "[2][5/12][349/390]\tLoss_D: -0.0412\tLoss_G: 0.1038\tD(x): -0.0629\tD(G(z)): -0.1042 / -0.1038\n",
            "[0][5/12][359/390]\tLoss_D: -0.0425\tLoss_G: 0.1083\tD(x): -0.0606\tD(G(z)): -0.1031 / -0.1083\n",
            "[1][5/12][369/390]\tLoss_D: -0.0458\tLoss_G: 0.1070\tD(x): -0.0597\tD(G(z)): -0.1055 / -0.1070\n",
            "[2][5/12][379/390]\tLoss_D: -0.0428\tLoss_G: 0.1061\tD(x): -0.0603\tD(G(z)): -0.1031 / -0.1061\n",
            "[0][5/12][389/390]\tLoss_D: -0.0435\tLoss_G: 0.1058\tD(x): -0.0615\tD(G(z)): -0.1050 / -0.1058\n",
            "[2][6/12][9/390]\tLoss_D: -0.0425\tLoss_G: 0.1055\tD(x): -0.0614\tD(G(z)): -0.1039 / -0.1055\n",
            "[0][6/12][19/390]\tLoss_D: -0.0435\tLoss_G: 0.1066\tD(x): -0.0616\tD(G(z)): -0.1052 / -0.1066\n",
            "[1][6/12][29/390]\tLoss_D: -0.0446\tLoss_G: 0.1064\tD(x): -0.0588\tD(G(z)): -0.1035 / -0.1064\n",
            "[2][6/12][39/390]\tLoss_D: -0.0446\tLoss_G: 0.1055\tD(x): -0.0619\tD(G(z)): -0.1065 / -0.1055\n",
            "[0][6/12][49/390]\tLoss_D: -0.0461\tLoss_G: 0.1039\tD(x): -0.0604\tD(G(z)): -0.1065 / -0.1039\n",
            "[1][6/12][59/390]\tLoss_D: -0.0458\tLoss_G: 0.1055\tD(x): -0.0600\tD(G(z)): -0.1058 / -0.1055\n",
            "[2][6/12][69/390]\tLoss_D: -0.0448\tLoss_G: 0.1039\tD(x): -0.0607\tD(G(z)): -0.1055 / -0.1039\n",
            "[0][6/12][79/390]\tLoss_D: -0.0435\tLoss_G: 0.1062\tD(x): -0.0596\tD(G(z)): -0.1031 / -0.1062\n",
            "[1][6/12][89/390]\tLoss_D: -0.0440\tLoss_G: 0.1056\tD(x): -0.0608\tD(G(z)): -0.1048 / -0.1056\n",
            "[2][6/12][99/390]\tLoss_D: -0.0443\tLoss_G: 0.1033\tD(x): -0.0625\tD(G(z)): -0.1068 / -0.1033\n",
            "[0][6/12][109/390]\tLoss_D: -0.0437\tLoss_G: 0.1075\tD(x): -0.0599\tD(G(z)): -0.1036 / -0.1075\n",
            "[1][6/12][119/390]\tLoss_D: -0.0462\tLoss_G: 0.1059\tD(x): -0.0591\tD(G(z)): -0.1053 / -0.1059\n",
            "[2][6/12][129/390]\tLoss_D: -0.0405\tLoss_G: 0.1081\tD(x): -0.0621\tD(G(z)): -0.1026 / -0.1081\n",
            "[0][6/12][139/390]\tLoss_D: -0.0432\tLoss_G: 0.1065\tD(x): -0.0607\tD(G(z)): -0.1039 / -0.1065\n",
            "[1][6/12][149/390]\tLoss_D: -0.0476\tLoss_G: 0.1051\tD(x): -0.0587\tD(G(z)): -0.1063 / -0.1051\n",
            "[2][6/12][159/390]\tLoss_D: -0.0431\tLoss_G: 0.1032\tD(x): -0.0610\tD(G(z)): -0.1041 / -0.1032\n",
            "[0][6/12][169/390]\tLoss_D: -0.0443\tLoss_G: 0.1032\tD(x): -0.0622\tD(G(z)): -0.1065 / -0.1032\n",
            "[1][6/12][179/390]\tLoss_D: -0.0481\tLoss_G: 0.1049\tD(x): -0.0587\tD(G(z)): -0.1068 / -0.1049\n",
            "[2][6/12][189/390]\tLoss_D: -0.0434\tLoss_G: 0.1056\tD(x): -0.0618\tD(G(z)): -0.1052 / -0.1056\n",
            "[0][6/12][199/390]\tLoss_D: -0.0454\tLoss_G: 0.1065\tD(x): -0.0598\tD(G(z)): -0.1052 / -0.1065\n",
            "[1][6/12][209/390]\tLoss_D: -0.0459\tLoss_G: 0.1060\tD(x): -0.0590\tD(G(z)): -0.1049 / -0.1060\n",
            "[2][6/12][219/390]\tLoss_D: -0.0418\tLoss_G: 0.1058\tD(x): -0.0622\tD(G(z)): -0.1040 / -0.1058\n",
            "[0][6/12][229/390]\tLoss_D: -0.0416\tLoss_G: 0.1076\tD(x): -0.0599\tD(G(z)): -0.1015 / -0.1076\n",
            "[1][6/12][239/390]\tLoss_D: -0.0465\tLoss_G: 0.1065\tD(x): -0.0592\tD(G(z)): -0.1057 / -0.1065\n",
            "[2][6/12][249/390]\tLoss_D: -0.0423\tLoss_G: 0.1036\tD(x): -0.0619\tD(G(z)): -0.1042 / -0.1036\n",
            "[0][6/12][259/390]\tLoss_D: -0.0434\tLoss_G: 0.1071\tD(x): -0.0598\tD(G(z)): -0.1032 / -0.1071\n",
            "[1][6/12][269/390]\tLoss_D: -0.0469\tLoss_G: 0.1058\tD(x): -0.0595\tD(G(z)): -0.1064 / -0.1058\n",
            "[2][6/12][279/390]\tLoss_D: -0.0386\tLoss_G: 0.1062\tD(x): -0.0646\tD(G(z)): -0.1032 / -0.1062\n",
            "[0][6/12][289/390]\tLoss_D: -0.0395\tLoss_G: 0.1060\tD(x): -0.0611\tD(G(z)): -0.1006 / -0.1060\n",
            "[1][6/12][299/390]\tLoss_D: -0.0452\tLoss_G: 0.1065\tD(x): -0.0610\tD(G(z)): -0.1062 / -0.1065\n",
            "[2][6/12][309/390]\tLoss_D: -0.0379\tLoss_G: 0.1043\tD(x): -0.0638\tD(G(z)): -0.1017 / -0.1043\n",
            "[0][6/12][319/390]\tLoss_D: -0.0414\tLoss_G: 0.1057\tD(x): -0.0595\tD(G(z)): -0.1009 / -0.1057\n",
            "[1][6/12][329/390]\tLoss_D: -0.0484\tLoss_G: 0.1037\tD(x): -0.0592\tD(G(z)): -0.1076 / -0.1037\n",
            "[2][6/12][339/390]\tLoss_D: -0.0413\tLoss_G: 0.1031\tD(x): -0.0627\tD(G(z)): -0.1040 / -0.1031\n",
            "[0][6/12][349/390]\tLoss_D: -0.0410\tLoss_G: 0.1045\tD(x): -0.0619\tD(G(z)): -0.1029 / -0.1045\n",
            "[1][6/12][359/390]\tLoss_D: -0.0468\tLoss_G: 0.1065\tD(x): -0.0598\tD(G(z)): -0.1066 / -0.1065\n",
            "[2][6/12][369/390]\tLoss_D: -0.0434\tLoss_G: 0.1070\tD(x): -0.0627\tD(G(z)): -0.1061 / -0.1070\n",
            "[0][6/12][379/390]\tLoss_D: -0.0420\tLoss_G: 0.1054\tD(x): -0.0613\tD(G(z)): -0.1033 / -0.1054\n",
            "[1][6/12][389/390]\tLoss_D: -0.0451\tLoss_G: 0.1061\tD(x): -0.0603\tD(G(z)): -0.1054 / -0.1061\n",
            "[0][7/12][9/390]\tLoss_D: -0.0434\tLoss_G: 0.1038\tD(x): -0.0613\tD(G(z)): -0.1047 / -0.1038\n",
            "[1][7/12][19/390]\tLoss_D: -0.0469\tLoss_G: 0.1055\tD(x): -0.0591\tD(G(z)): -0.1060 / -0.1055\n",
            "[2][7/12][29/390]\tLoss_D: -0.0380\tLoss_G: 0.1041\tD(x): -0.0611\tD(G(z)): -0.0991 / -0.1041\n",
            "[0][7/12][39/390]\tLoss_D: -0.0429\tLoss_G: 0.1041\tD(x): -0.0611\tD(G(z)): -0.1040 / -0.1041\n",
            "[1][7/12][49/390]\tLoss_D: -0.0461\tLoss_G: 0.1049\tD(x): -0.0605\tD(G(z)): -0.1065 / -0.1049\n",
            "[2][7/12][59/390]\tLoss_D: -0.0363\tLoss_G: 0.1048\tD(x): -0.0665\tD(G(z)): -0.1028 / -0.1048\n",
            "[0][7/12][69/390]\tLoss_D: -0.0401\tLoss_G: 0.1044\tD(x): -0.0624\tD(G(z)): -0.1025 / -0.1044\n",
            "[1][7/12][79/390]\tLoss_D: -0.0453\tLoss_G: 0.1046\tD(x): -0.0604\tD(G(z)): -0.1057 / -0.1046\n",
            "[2][7/12][89/390]\tLoss_D: -0.0369\tLoss_G: 0.1062\tD(x): -0.0626\tD(G(z)): -0.0995 / -0.1062\n",
            "[0][7/12][99/390]\tLoss_D: -0.0432\tLoss_G: 0.1026\tD(x): -0.0622\tD(G(z)): -0.1054 / -0.1026\n",
            "[1][7/12][109/390]\tLoss_D: -0.0449\tLoss_G: 0.1049\tD(x): -0.0606\tD(G(z)): -0.1055 / -0.1049\n",
            "[2][7/12][119/390]\tLoss_D: -0.0418\tLoss_G: 0.1010\tD(x): -0.0645\tD(G(z)): -0.1063 / -0.1010\n",
            "[0][7/12][129/390]\tLoss_D: -0.0392\tLoss_G: 0.1072\tD(x): -0.0622\tD(G(z)): -0.1014 / -0.1072\n",
            "[1][7/12][139/390]\tLoss_D: -0.0445\tLoss_G: 0.1056\tD(x): -0.0613\tD(G(z)): -0.1058 / -0.1056\n",
            "[2][7/12][149/390]\tLoss_D: -0.0324\tLoss_G: 0.1058\tD(x): -0.0609\tD(G(z)): -0.0934 / -0.1058\n",
            "[0][7/12][159/390]\tLoss_D: -0.0371\tLoss_G: 0.0983\tD(x): -0.0645\tD(G(z)): -0.1015 / -0.0983\n",
            "[1][7/12][169/390]\tLoss_D: -0.0463\tLoss_G: 0.1049\tD(x): -0.0598\tD(G(z)): -0.1061 / -0.1049\n",
            "[2][7/12][179/390]\tLoss_D: -0.0407\tLoss_G: 0.1054\tD(x): -0.0634\tD(G(z)): -0.1041 / -0.1054\n",
            "[0][7/12][189/390]\tLoss_D: -0.0444\tLoss_G: 0.1013\tD(x): -0.0623\tD(G(z)): -0.1067 / -0.1013\n",
            "[1][7/12][199/390]\tLoss_D: -0.0460\tLoss_G: 0.1067\tD(x): -0.0594\tD(G(z)): -0.1054 / -0.1067\n",
            "[2][7/12][209/390]\tLoss_D: -0.0363\tLoss_G: 0.1020\tD(x): -0.0693\tD(G(z)): -0.1057 / -0.1020\n",
            "[0][7/12][219/390]\tLoss_D: -0.0454\tLoss_G: 0.1061\tD(x): -0.0623\tD(G(z)): -0.1077 / -0.1061\n",
            "[1][7/12][229/390]\tLoss_D: -0.0467\tLoss_G: 0.1057\tD(x): -0.0590\tD(G(z)): -0.1057 / -0.1057\n",
            "[2][7/12][239/390]\tLoss_D: -0.0400\tLoss_G: 0.1047\tD(x): -0.0631\tD(G(z)): -0.1031 / -0.1047\n",
            "[0][7/12][249/390]\tLoss_D: -0.0325\tLoss_G: 0.1051\tD(x): -0.0639\tD(G(z)): -0.0964 / -0.1051\n",
            "[1][7/12][259/390]\tLoss_D: -0.0453\tLoss_G: 0.1080\tD(x): -0.0604\tD(G(z)): -0.1056 / -0.1080\n",
            "[2][7/12][269/390]\tLoss_D: -0.0393\tLoss_G: 0.1017\tD(x): -0.0652\tD(G(z)): -0.1046 / -0.1017\n",
            "[0][7/12][279/390]\tLoss_D: -0.0391\tLoss_G: 0.1021\tD(x): -0.0635\tD(G(z)): -0.1026 / -0.1021\n",
            "[1][7/12][289/390]\tLoss_D: -0.0486\tLoss_G: 0.1071\tD(x): -0.0593\tD(G(z)): -0.1079 / -0.1071\n",
            "[2][7/12][299/390]\tLoss_D: -0.0347\tLoss_G: 0.1066\tD(x): -0.0631\tD(G(z)): -0.0978 / -0.1066\n",
            "[0][7/12][309/390]\tLoss_D: -0.0400\tLoss_G: 0.1003\tD(x): -0.0637\tD(G(z)): -0.1037 / -0.1003\n",
            "[1][7/12][319/390]\tLoss_D: -0.0463\tLoss_G: 0.1061\tD(x): -0.0598\tD(G(z)): -0.1061 / -0.1061\n",
            "[2][7/12][329/390]\tLoss_D: -0.0414\tLoss_G: 0.1036\tD(x): -0.0639\tD(G(z)): -0.1054 / -0.1036\n",
            "[0][7/12][339/390]\tLoss_D: -0.0420\tLoss_G: 0.1018\tD(x): -0.0636\tD(G(z)): -0.1056 / -0.1018\n",
            "[1][7/12][349/390]\tLoss_D: -0.0474\tLoss_G: 0.1057\tD(x): -0.0598\tD(G(z)): -0.1072 / -0.1057\n",
            "[2][7/12][359/390]\tLoss_D: -0.0422\tLoss_G: 0.1061\tD(x): -0.0632\tD(G(z)): -0.1054 / -0.1061\n",
            "[0][7/12][369/390]\tLoss_D: -0.0450\tLoss_G: 0.1022\tD(x): -0.0608\tD(G(z)): -0.1058 / -0.1022\n",
            "[1][7/12][379/390]\tLoss_D: -0.0449\tLoss_G: 0.1050\tD(x): -0.0607\tD(G(z)): -0.1056 / -0.1050\n",
            "[2][7/12][389/390]\tLoss_D: -0.0376\tLoss_G: 0.1035\tD(x): -0.0657\tD(G(z)): -0.1033 / -0.1035\n",
            "[1][8/12][9/390]\tLoss_D: -0.0461\tLoss_G: 0.1055\tD(x): -0.0599\tD(G(z)): -0.1060 / -0.1055\n",
            "[2][8/12][19/390]\tLoss_D: -0.0420\tLoss_G: 0.1055\tD(x): -0.0638\tD(G(z)): -0.1057 / -0.1055\n",
            "[0][8/12][29/390]\tLoss_D: -0.0383\tLoss_G: 0.1054\tD(x): -0.0609\tD(G(z)): -0.0992 / -0.1054\n",
            "[1][8/12][39/390]\tLoss_D: -0.0423\tLoss_G: 0.1064\tD(x): -0.0616\tD(G(z)): -0.1039 / -0.1064\n",
            "[2][8/12][49/390]\tLoss_D: -0.0329\tLoss_G: 0.1061\tD(x): -0.0615\tD(G(z)): -0.0944 / -0.1061\n",
            "[0][8/12][59/390]\tLoss_D: -0.0427\tLoss_G: 0.1021\tD(x): -0.0631\tD(G(z)): -0.1058 / -0.1021\n",
            "[1][8/12][69/390]\tLoss_D: -0.0449\tLoss_G: 0.1052\tD(x): -0.0606\tD(G(z)): -0.1055 / -0.1052\n",
            "[2][8/12][79/390]\tLoss_D: -0.0310\tLoss_G: 0.1071\tD(x): -0.0620\tD(G(z)): -0.0931 / -0.1071\n",
            "[0][8/12][89/390]\tLoss_D: -0.0379\tLoss_G: 0.1061\tD(x): -0.0618\tD(G(z)): -0.0997 / -0.1061\n",
            "[1][8/12][99/390]\tLoss_D: -0.0453\tLoss_G: 0.1052\tD(x): -0.0601\tD(G(z)): -0.1054 / -0.1052\n",
            "[2][8/12][109/390]\tLoss_D: -0.0360\tLoss_G: 0.1066\tD(x): -0.0633\tD(G(z)): -0.0993 / -0.1066\n",
            "[0][8/12][119/390]\tLoss_D: -0.0398\tLoss_G: 0.0973\tD(x): -0.0671\tD(G(z)): -0.1069 / -0.0973\n",
            "[1][8/12][129/390]\tLoss_D: -0.0455\tLoss_G: 0.1058\tD(x): -0.0598\tD(G(z)): -0.1054 / -0.1058\n",
            "[2][8/12][139/390]\tLoss_D: -0.0419\tLoss_G: 0.1029\tD(x): -0.0631\tD(G(z)): -0.1050 / -0.1029\n",
            "[0][8/12][149/390]\tLoss_D: -0.0395\tLoss_G: 0.1007\tD(x): -0.0643\tD(G(z)): -0.1038 / -0.1007\n",
            "[1][8/12][159/390]\tLoss_D: -0.0436\tLoss_G: 0.1057\tD(x): -0.0599\tD(G(z)): -0.1036 / -0.1057\n",
            "[2][8/12][169/390]\tLoss_D: -0.0380\tLoss_G: 0.1020\tD(x): -0.0671\tD(G(z)): -0.1051 / -0.1020\n",
            "[0][8/12][179/390]\tLoss_D: -0.0387\tLoss_G: 0.1054\tD(x): -0.0611\tD(G(z)): -0.0998 / -0.1054\n",
            "[1][8/12][189/390]\tLoss_D: -0.0440\tLoss_G: 0.1055\tD(x): -0.0600\tD(G(z)): -0.1040 / -0.1055\n",
            "[2][8/12][199/390]\tLoss_D: -0.0380\tLoss_G: 0.1051\tD(x): -0.0639\tD(G(z)): -0.1019 / -0.1051\n",
            "[0][8/12][209/390]\tLoss_D: -0.0355\tLoss_G: 0.1049\tD(x): -0.0628\tD(G(z)): -0.0983 / -0.1049\n",
            "[1][8/12][219/390]\tLoss_D: -0.0430\tLoss_G: 0.1062\tD(x): -0.0609\tD(G(z)): -0.1039 / -0.1062\n",
            "[2][8/12][229/390]\tLoss_D: -0.0390\tLoss_G: 0.1029\tD(x): -0.0626\tD(G(z)): -0.1016 / -0.1029\n",
            "[0][8/12][239/390]\tLoss_D: -0.0378\tLoss_G: 0.1056\tD(x): -0.0623\tD(G(z)): -0.1001 / -0.1056\n",
            "[1][8/12][249/390]\tLoss_D: -0.0461\tLoss_G: 0.1054\tD(x): -0.0598\tD(G(z)): -0.1059 / -0.1054\n",
            "[2][8/12][259/390]\tLoss_D: -0.0354\tLoss_G: 0.1027\tD(x): -0.0688\tD(G(z)): -0.1042 / -0.1027\n",
            "[0][8/12][269/390]\tLoss_D: -0.0394\tLoss_G: 0.0989\tD(x): -0.0657\tD(G(z)): -0.1051 / -0.0989\n",
            "[1][8/12][279/390]\tLoss_D: -0.0444\tLoss_G: 0.1054\tD(x): -0.0604\tD(G(z)): -0.1048 / -0.1054\n",
            "[2][8/12][289/390]\tLoss_D: -0.0361\tLoss_G: 0.1022\tD(x): -0.0641\tD(G(z)): -0.1002 / -0.1022\n",
            "[0][8/12][299/390]\tLoss_D: -0.0439\tLoss_G: 0.1051\tD(x): -0.0631\tD(G(z)): -0.1070 / -0.1051\n",
            "[1][8/12][309/390]\tLoss_D: -0.0436\tLoss_G: 0.1037\tD(x): -0.0615\tD(G(z)): -0.1051 / -0.1037\n",
            "[2][8/12][319/390]\tLoss_D: -0.0340\tLoss_G: 0.1065\tD(x): -0.0639\tD(G(z)): -0.0978 / -0.1065\n",
            "[0][8/12][329/390]\tLoss_D: -0.0397\tLoss_G: 0.1016\tD(x): -0.0637\tD(G(z)): -0.1033 / -0.1016\n",
            "[1][8/12][339/390]\tLoss_D: -0.0444\tLoss_G: 0.1025\tD(x): -0.0607\tD(G(z)): -0.1051 / -0.1025\n",
            "[2][8/12][349/390]\tLoss_D: -0.0394\tLoss_G: 0.1041\tD(x): -0.0635\tD(G(z)): -0.1030 / -0.1041\n",
            "[0][8/12][359/390]\tLoss_D: -0.0418\tLoss_G: 0.1042\tD(x): -0.0663\tD(G(z)): -0.1081 / -0.1042\n",
            "[1][8/12][369/390]\tLoss_D: -0.0447\tLoss_G: 0.1033\tD(x): -0.0618\tD(G(z)): -0.1065 / -0.1033\n",
            "[2][8/12][379/390]\tLoss_D: -0.0373\tLoss_G: 0.0996\tD(x): -0.0672\tD(G(z)): -0.1045 / -0.0996\n",
            "[0][8/12][389/390]\tLoss_D: -0.0398\tLoss_G: 0.1002\tD(x): -0.0641\tD(G(z)): -0.1039 / -0.1002\n",
            "[2][9/12][9/390]\tLoss_D: -0.0353\tLoss_G: 0.1059\tD(x): -0.0652\tD(G(z)): -0.1005 / -0.1059\n",
            "[0][9/12][19/390]\tLoss_D: -0.0417\tLoss_G: 0.1065\tD(x): -0.0652\tD(G(z)): -0.1069 / -0.1065\n",
            "[1][9/12][29/390]\tLoss_D: -0.0401\tLoss_G: 0.1082\tD(x): -0.0634\tD(G(z)): -0.1035 / -0.1082\n",
            "[2][9/12][39/390]\tLoss_D: -0.0402\tLoss_G: 0.1012\tD(x): -0.0631\tD(G(z)): -0.1033 / -0.1012\n",
            "[0][9/12][49/390]\tLoss_D: -0.0466\tLoss_G: 0.1080\tD(x): -0.0615\tD(G(z)): -0.1081 / -0.1080\n",
            "[1][9/12][59/390]\tLoss_D: -0.0466\tLoss_G: 0.1033\tD(x): -0.0611\tD(G(z)): -0.1076 / -0.1033\n",
            "[2][9/12][69/390]\tLoss_D: -0.0384\tLoss_G: 0.0999\tD(x): -0.0666\tD(G(z)): -0.1050 / -0.0999\n",
            "[0][9/12][79/390]\tLoss_D: -0.0384\tLoss_G: 0.1068\tD(x): -0.0622\tD(G(z)): -0.1006 / -0.1068\n",
            "[1][9/12][89/390]\tLoss_D: -0.0420\tLoss_G: 0.1084\tD(x): -0.0605\tD(G(z)): -0.1026 / -0.1084\n",
            "[2][9/12][99/390]\tLoss_D: -0.0349\tLoss_G: 0.0994\tD(x): -0.0695\tD(G(z)): -0.1043 / -0.0994\n",
            "[0][9/12][109/390]\tLoss_D: -0.0426\tLoss_G: 0.1009\tD(x): -0.0641\tD(G(z)): -0.1067 / -0.1009\n",
            "[1][9/12][119/390]\tLoss_D: -0.0457\tLoss_G: 0.1049\tD(x): -0.0594\tD(G(z)): -0.1051 / -0.1049\n",
            "[2][9/12][129/390]\tLoss_D: -0.0378\tLoss_G: 0.1023\tD(x): -0.0667\tD(G(z)): -0.1045 / -0.1023\n",
            "[0][9/12][139/390]\tLoss_D: -0.0395\tLoss_G: 0.1007\tD(x): -0.0660\tD(G(z)): -0.1055 / -0.1007\n",
            "[1][9/12][149/390]\tLoss_D: -0.0434\tLoss_G: 0.1052\tD(x): -0.0623\tD(G(z)): -0.1057 / -0.1052\n",
            "[2][9/12][159/390]\tLoss_D: -0.0362\tLoss_G: 0.0996\tD(x): -0.0694\tD(G(z)): -0.1056 / -0.0996\n",
            "[0][9/12][169/390]\tLoss_D: -0.0342\tLoss_G: 0.1053\tD(x): -0.0644\tD(G(z)): -0.0985 / -0.1053\n",
            "[1][9/12][179/390]\tLoss_D: -0.0439\tLoss_G: 0.1030\tD(x): -0.0620\tD(G(z)): -0.1059 / -0.1030\n",
            "[2][9/12][189/390]\tLoss_D: -0.0339\tLoss_G: 0.1020\tD(x): -0.0659\tD(G(z)): -0.0998 / -0.1020\n",
            "[0][9/12][199/390]\tLoss_D: -0.0438\tLoss_G: 0.1069\tD(x): -0.0637\tD(G(z)): -0.1075 / -0.1069\n",
            "[1][9/12][209/390]\tLoss_D: -0.0422\tLoss_G: 0.1058\tD(x): -0.0614\tD(G(z)): -0.1036 / -0.1058\n",
            "[2][9/12][219/390]\tLoss_D: -0.0337\tLoss_G: 0.1006\tD(x): -0.0657\tD(G(z)): -0.0994 / -0.1006\n",
            "[0][9/12][229/390]\tLoss_D: -0.0372\tLoss_G: 0.1079\tD(x): -0.0615\tD(G(z)): -0.0987 / -0.1079\n",
            "[1][9/12][239/390]\tLoss_D: -0.0432\tLoss_G: 0.1050\tD(x): -0.0607\tD(G(z)): -0.1039 / -0.1050\n",
            "[2][9/12][249/390]\tLoss_D: -0.0328\tLoss_G: 0.0974\tD(x): -0.0723\tD(G(z)): -0.1051 / -0.0974\n",
            "[0][9/12][259/390]\tLoss_D: -0.0423\tLoss_G: 0.1035\tD(x): -0.0655\tD(G(z)): -0.1077 / -0.1035\n",
            "[1][9/12][269/390]\tLoss_D: -0.0423\tLoss_G: 0.1067\tD(x): -0.0615\tD(G(z)): -0.1038 / -0.1067\n",
            "[2][9/12][279/390]\tLoss_D: -0.0322\tLoss_G: 0.1031\tD(x): -0.0646\tD(G(z)): -0.0969 / -0.1031\n",
            "[0][9/12][289/390]\tLoss_D: -0.0357\tLoss_G: 0.1069\tD(x): -0.0620\tD(G(z)): -0.0977 / -0.1069\n",
            "[1][9/12][299/390]\tLoss_D: -0.0433\tLoss_G: 0.1060\tD(x): -0.0620\tD(G(z)): -0.1053 / -0.1060\n",
            "[2][9/12][309/390]\tLoss_D: -0.0304\tLoss_G: 0.1034\tD(x): -0.0627\tD(G(z)): -0.0931 / -0.1034\n",
            "[0][9/12][319/390]\tLoss_D: -0.0441\tLoss_G: 0.1046\tD(x): -0.0617\tD(G(z)): -0.1059 / -0.1046\n",
            "[1][9/12][329/390]\tLoss_D: -0.0451\tLoss_G: 0.1039\tD(x): -0.0615\tD(G(z)): -0.1066 / -0.1039\n",
            "[2][9/12][339/390]\tLoss_D: -0.0312\tLoss_G: 0.1053\tD(x): -0.0631\tD(G(z)): -0.0943 / -0.1053\n",
            "[0][9/12][349/390]\tLoss_D: -0.0390\tLoss_G: 0.0991\tD(x): -0.0646\tD(G(z)): -0.1036 / -0.0991\n",
            "[1][9/12][359/390]\tLoss_D: -0.0449\tLoss_G: 0.1040\tD(x): -0.0618\tD(G(z)): -0.1067 / -0.1040\n",
            "[2][9/12][369/390]\tLoss_D: -0.0340\tLoss_G: 0.1011\tD(x): -0.0687\tD(G(z)): -0.1027 / -0.1011\n",
            "[0][9/12][379/390]\tLoss_D: -0.0397\tLoss_G: 0.0982\tD(x): -0.0642\tD(G(z)): -0.1038 / -0.0982\n",
            "[1][9/12][389/390]\tLoss_D: -0.0419\tLoss_G: 0.1063\tD(x): -0.0618\tD(G(z)): -0.1037 / -0.1063\n",
            "[0][10/12][9/390]\tLoss_D: -0.0427\tLoss_G: 0.1029\tD(x): -0.0616\tD(G(z)): -0.1043 / -0.1029\n",
            "[1][10/12][19/390]\tLoss_D: -0.0442\tLoss_G: 0.1053\tD(x): -0.0605\tD(G(z)): -0.1048 / -0.1053\n",
            "[2][10/12][29/390]\tLoss_D: -0.0328\tLoss_G: 0.0984\tD(x): -0.0689\tD(G(z)): -0.1017 / -0.0984\n",
            "[0][10/12][39/390]\tLoss_D: -0.0419\tLoss_G: 0.0981\tD(x): -0.0650\tD(G(z)): -0.1069 / -0.0981\n",
            "[1][10/12][49/390]\tLoss_D: -0.0446\tLoss_G: 0.1049\tD(x): -0.0612\tD(G(z)): -0.1058 / -0.1049\n",
            "[2][10/12][59/390]\tLoss_D: -0.0267\tLoss_G: 0.1010\tD(x): -0.0656\tD(G(z)): -0.0923 / -0.1010\n",
            "[0][10/12][69/390]\tLoss_D: -0.0387\tLoss_G: 0.0990\tD(x): -0.0649\tD(G(z)): -0.1036 / -0.0990\n",
            "[1][10/12][79/390]\tLoss_D: -0.0434\tLoss_G: 0.1049\tD(x): -0.0613\tD(G(z)): -0.1046 / -0.1049\n",
            "[2][10/12][89/390]\tLoss_D: -0.0366\tLoss_G: 0.0984\tD(x): -0.0687\tD(G(z)): -0.1053 / -0.0984\n",
            "[0][10/12][99/390]\tLoss_D: -0.0392\tLoss_G: 0.0998\tD(x): -0.0678\tD(G(z)): -0.1070 / -0.0998\n",
            "[1][10/12][109/390]\tLoss_D: -0.0444\tLoss_G: 0.1054\tD(x): -0.0609\tD(G(z)): -0.1053 / -0.1054\n",
            "[2][10/12][119/390]\tLoss_D: -0.0348\tLoss_G: 0.1011\tD(x): -0.0683\tD(G(z)): -0.1031 / -0.1011\n",
            "[0][10/12][129/390]\tLoss_D: -0.0341\tLoss_G: 0.1048\tD(x): -0.0650\tD(G(z)): -0.0990 / -0.1048\n",
            "[1][10/12][139/390]\tLoss_D: -0.0421\tLoss_G: 0.1047\tD(x): -0.0611\tD(G(z)): -0.1032 / -0.1047\n",
            "[2][10/12][149/390]\tLoss_D: -0.0319\tLoss_G: 0.1016\tD(x): -0.0676\tD(G(z)): -0.0995 / -0.1016\n",
            "[0][10/12][159/390]\tLoss_D: -0.0338\tLoss_G: 0.1047\tD(x): -0.0637\tD(G(z)): -0.0975 / -0.1047\n",
            "[1][10/12][169/390]\tLoss_D: -0.0389\tLoss_G: 0.1054\tD(x): -0.0624\tD(G(z)): -0.1012 / -0.1054\n",
            "[2][10/12][179/390]\tLoss_D: -0.0369\tLoss_G: 0.1041\tD(x): -0.0639\tD(G(z)): -0.1009 / -0.1041\n",
            "[0][10/12][189/390]\tLoss_D: -0.0393\tLoss_G: 0.0985\tD(x): -0.0656\tD(G(z)): -0.1049 / -0.0985\n",
            "[1][10/12][199/390]\tLoss_D: -0.0396\tLoss_G: 0.1066\tD(x): -0.0609\tD(G(z)): -0.1005 / -0.1066\n",
            "[2][10/12][209/390]\tLoss_D: -0.0310\tLoss_G: 0.1001\tD(x): -0.0719\tD(G(z)): -0.1029 / -0.1001\n",
            "[0][10/12][219/390]\tLoss_D: -0.0358\tLoss_G: 0.1035\tD(x): -0.0656\tD(G(z)): -0.1014 / -0.1035\n",
            "[1][10/12][229/390]\tLoss_D: -0.0435\tLoss_G: 0.1035\tD(x): -0.0615\tD(G(z)): -0.1050 / -0.1035\n",
            "[2][10/12][239/390]\tLoss_D: -0.0310\tLoss_G: 0.1024\tD(x): -0.0663\tD(G(z)): -0.0973 / -0.1024\n",
            "[0][10/12][249/390]\tLoss_D: -0.0299\tLoss_G: 0.1076\tD(x): -0.0638\tD(G(z)): -0.0937 / -0.1076\n",
            "[1][10/12][259/390]\tLoss_D: -0.0441\tLoss_G: 0.1022\tD(x): -0.0619\tD(G(z)): -0.1060 / -0.1022\n",
            "[2][10/12][269/390]\tLoss_D: -0.0314\tLoss_G: 0.1049\tD(x): -0.0644\tD(G(z)): -0.0958 / -0.1049\n",
            "[0][10/12][279/390]\tLoss_D: -0.0414\tLoss_G: 0.1051\tD(x): -0.0627\tD(G(z)): -0.1041 / -0.1051\n",
            "[1][10/12][289/390]\tLoss_D: -0.0386\tLoss_G: 0.1059\tD(x): -0.0627\tD(G(z)): -0.1013 / -0.1059\n",
            "[2][10/12][299/390]\tLoss_D: -0.0332\tLoss_G: 0.0968\tD(x): -0.0708\tD(G(z)): -0.1040 / -0.0968\n",
            "[0][10/12][309/390]\tLoss_D: -0.0359\tLoss_G: 0.1032\tD(x): -0.0653\tD(G(z)): -0.1012 / -0.1032\n",
            "[1][10/12][319/390]\tLoss_D: -0.0410\tLoss_G: 0.1041\tD(x): -0.0619\tD(G(z)): -0.1029 / -0.1041\n",
            "[2][10/12][329/390]\tLoss_D: -0.0342\tLoss_G: 0.1036\tD(x): -0.0651\tD(G(z)): -0.0993 / -0.1036\n",
            "[0][10/12][339/390]\tLoss_D: -0.0376\tLoss_G: 0.1042\tD(x): -0.0642\tD(G(z)): -0.1018 / -0.1042\n",
            "[1][10/12][349/390]\tLoss_D: -0.0425\tLoss_G: 0.1050\tD(x): -0.0614\tD(G(z)): -0.1039 / -0.1050\n",
            "[2][10/12][359/390]\tLoss_D: -0.0251\tLoss_G: 0.1058\tD(x): -0.0633\tD(G(z)): -0.0884 / -0.1058\n",
            "[0][10/12][369/390]\tLoss_D: -0.0388\tLoss_G: 0.1050\tD(x): -0.0620\tD(G(z)): -0.1008 / -0.1050\n",
            "[1][10/12][379/390]\tLoss_D: -0.0387\tLoss_G: 0.1053\tD(x): -0.0638\tD(G(z)): -0.1026 / -0.1053\n",
            "[2][10/12][389/390]\tLoss_D: -0.0250\tLoss_G: 0.1050\tD(x): -0.0652\tD(G(z)): -0.0902 / -0.1050\n",
            "[1][11/12][9/390]\tLoss_D: -0.0425\tLoss_G: 0.1034\tD(x): -0.0612\tD(G(z)): -0.1036 / -0.1034\n",
            "[2][11/12][19/390]\tLoss_D: -0.0317\tLoss_G: 0.0964\tD(x): -0.0741\tD(G(z)): -0.1058 / -0.0964\n",
            "[0][11/12][29/390]\tLoss_D: -0.0346\tLoss_G: 0.0947\tD(x): -0.0675\tD(G(z)): -0.1021 / -0.0947\n",
            "[1][11/12][39/390]\tLoss_D: -0.0416\tLoss_G: 0.1051\tD(x): -0.0631\tD(G(z)): -0.1047 / -0.1051\n",
            "[2][11/12][49/390]\tLoss_D: -0.0286\tLoss_G: 0.1024\tD(x): -0.0678\tD(G(z)): -0.0963 / -0.1024\n",
            "[0][11/12][59/390]\tLoss_D: -0.0333\tLoss_G: 0.1059\tD(x): -0.0649\tD(G(z)): -0.0982 / -0.1059\n",
            "[1][11/12][69/390]\tLoss_D: -0.0443\tLoss_G: 0.1021\tD(x): -0.0620\tD(G(z)): -0.1063 / -0.1021\n",
            "[2][11/12][79/390]\tLoss_D: -0.0280\tLoss_G: 0.1063\tD(x): -0.0664\tD(G(z)): -0.0943 / -0.1063\n",
            "[0][11/12][89/390]\tLoss_D: -0.0329\tLoss_G: 0.1077\tD(x): -0.0630\tD(G(z)): -0.0959 / -0.1077\n",
            "[1][11/12][99/390]\tLoss_D: -0.0407\tLoss_G: 0.1048\tD(x): -0.0618\tD(G(z)): -0.1025 / -0.1048\n",
            "[2][11/12][109/390]\tLoss_D: -0.0282\tLoss_G: 0.0877\tD(x): -0.0751\tD(G(z)): -0.1033 / -0.0877\n",
            "[0][11/12][119/390]\tLoss_D: -0.0301\tLoss_G: 0.1047\tD(x): -0.0647\tD(G(z)): -0.0949 / -0.1047\n",
            "[1][11/12][129/390]\tLoss_D: -0.0396\tLoss_G: 0.1050\tD(x): -0.0630\tD(G(z)): -0.1025 / -0.1050\n",
            "[2][11/12][139/390]\tLoss_D: -0.0303\tLoss_G: 0.0932\tD(x): -0.0756\tD(G(z)): -0.1059 / -0.0932\n",
            "[0][11/12][149/390]\tLoss_D: -0.0408\tLoss_G: 0.0976\tD(x): -0.0644\tD(G(z)): -0.1052 / -0.0976\n",
            "[1][11/12][159/390]\tLoss_D: -0.0418\tLoss_G: 0.1065\tD(x): -0.0612\tD(G(z)): -0.1030 / -0.1065\n",
            "[2][11/12][169/390]\tLoss_D: -0.0316\tLoss_G: 0.0931\tD(x): -0.0740\tD(G(z)): -0.1057 / -0.0931\n",
            "[0][11/12][179/390]\tLoss_D: -0.0329\tLoss_G: 0.1059\tD(x): -0.0627\tD(G(z)): -0.0956 / -0.1059\n",
            "[1][11/12][189/390]\tLoss_D: -0.0420\tLoss_G: 0.1025\tD(x): -0.0617\tD(G(z)): -0.1037 / -0.1025\n",
            "[2][11/12][199/390]\tLoss_D: -0.0299\tLoss_G: 0.0938\tD(x): -0.0751\tD(G(z)): -0.1050 / -0.0938\n",
            "[0][11/12][209/390]\tLoss_D: -0.0402\tLoss_G: 0.1005\tD(x): -0.0660\tD(G(z)): -0.1063 / -0.1005\n",
            "[1][11/12][219/390]\tLoss_D: -0.0388\tLoss_G: 0.1033\tD(x): -0.0622\tD(G(z)): -0.1010 / -0.1033\n",
            "[2][11/12][229/390]\tLoss_D: -0.0310\tLoss_G: 0.0987\tD(x): -0.0698\tD(G(z)): -0.1009 / -0.0987\n",
            "[0][11/12][239/390]\tLoss_D: -0.0319\tLoss_G: 0.1074\tD(x): -0.0622\tD(G(z)): -0.0942 / -0.1074\n",
            "[1][11/12][249/390]\tLoss_D: -0.0395\tLoss_G: 0.1039\tD(x): -0.0622\tD(G(z)): -0.1016 / -0.1039\n",
            "[2][11/12][259/390]\tLoss_D: -0.0309\tLoss_G: 0.1013\tD(x): -0.0654\tD(G(z)): -0.0963 / -0.1013\n",
            "[0][11/12][269/390]\tLoss_D: -0.0376\tLoss_G: 0.1044\tD(x): -0.0617\tD(G(z)): -0.0993 / -0.1044\n",
            "[1][11/12][279/390]\tLoss_D: -0.0415\tLoss_G: 0.1022\tD(x): -0.0622\tD(G(z)): -0.1037 / -0.1022\n",
            "[2][11/12][289/390]\tLoss_D: -0.0266\tLoss_G: 0.1043\tD(x): -0.0638\tD(G(z)): -0.0904 / -0.1043\n",
            "[0][11/12][299/390]\tLoss_D: -0.0384\tLoss_G: 0.0982\tD(x): -0.0665\tD(G(z)): -0.1049 / -0.0982\n",
            "[1][11/12][309/390]\tLoss_D: -0.0437\tLoss_G: 0.1037\tD(x): -0.0628\tD(G(z)): -0.1064 / -0.1037\n",
            "[2][11/12][319/390]\tLoss_D: -0.0297\tLoss_G: 0.1017\tD(x): -0.0714\tD(G(z)): -0.1011 / -0.1017\n",
            "[0][11/12][329/390]\tLoss_D: -0.0370\tLoss_G: 0.0987\tD(x): -0.0634\tD(G(z)): -0.1005 / -0.0987\n",
            "[1][11/12][339/390]\tLoss_D: -0.0374\tLoss_G: 0.1071\tD(x): -0.0649\tD(G(z)): -0.1023 / -0.1071\n",
            "[2][11/12][349/390]\tLoss_D: -0.0293\tLoss_G: 0.0929\tD(x): -0.0752\tD(G(z)): -0.1045 / -0.0929\n",
            "[0][11/12][359/390]\tLoss_D: -0.0358\tLoss_G: 0.1048\tD(x): -0.0633\tD(G(z)): -0.0991 / -0.1048\n",
            "[1][11/12][369/390]\tLoss_D: -0.0414\tLoss_G: 0.1025\tD(x): -0.0646\tD(G(z)): -0.1059 / -0.1025\n",
            "[2][11/12][379/390]\tLoss_D: -0.0265\tLoss_G: 0.0866\tD(x): -0.0783\tD(G(z)): -0.1048 / -0.0866\n",
            "[0][11/12][389/390]\tLoss_D: -0.0365\tLoss_G: 0.1062\tD(x): -0.0626\tD(G(z)): -0.0991 / -0.1062\n",
            "[2][12/12][9/390]\tLoss_D: -0.0276\tLoss_G: 0.1025\tD(x): -0.0686\tD(G(z)): -0.0962 / -0.1025\n",
            "[0][12/12][19/390]\tLoss_D: -0.0383\tLoss_G: 0.1043\tD(x): -0.0624\tD(G(z)): -0.1008 / -0.1043\n",
            "[1][12/12][29/390]\tLoss_D: -0.0350\tLoss_G: 0.1050\tD(x): -0.0636\tD(G(z)): -0.0986 / -0.1050\n",
            "[2][12/12][39/390]\tLoss_D: -0.0273\tLoss_G: 0.0988\tD(x): -0.0710\tD(G(z)): -0.0983 / -0.0988\n",
            "[0][12/12][49/390]\tLoss_D: -0.0386\tLoss_G: 0.1004\tD(x): -0.0655\tD(G(z)): -0.1040 / -0.1004\n",
            "[1][12/12][59/390]\tLoss_D: -0.0387\tLoss_G: 0.1031\tD(x): -0.0620\tD(G(z)): -0.1007 / -0.1031\n",
            "[2][12/12][69/390]\tLoss_D: -0.0268\tLoss_G: 0.1053\tD(x): -0.0694\tD(G(z)): -0.0963 / -0.1053\n",
            "[0][12/12][79/390]\tLoss_D: -0.0347\tLoss_G: 0.1021\tD(x): -0.0646\tD(G(z)): -0.0993 / -0.1021\n",
            "[1][12/12][89/390]\tLoss_D: -0.0372\tLoss_G: 0.1035\tD(x): -0.0640\tD(G(z)): -0.1012 / -0.1035\n",
            "[2][12/12][99/390]\tLoss_D: -0.0298\tLoss_G: 0.0970\tD(x): -0.0717\tD(G(z)): -0.1015 / -0.0970\n",
            "[0][12/12][109/390]\tLoss_D: -0.0428\tLoss_G: 0.1028\tD(x): -0.0606\tD(G(z)): -0.1034 / -0.1028\n",
            "[1][12/12][119/390]\tLoss_D: -0.0380\tLoss_G: 0.1047\tD(x): -0.0636\tD(G(z)): -0.1016 / -0.1047\n",
            "[2][12/12][129/390]\tLoss_D: -0.0291\tLoss_G: 0.0922\tD(x): -0.0757\tD(G(z)): -0.1048 / -0.0922\n",
            "[0][12/12][139/390]\tLoss_D: -0.0409\tLoss_G: 0.0996\tD(x): -0.0633\tD(G(z)): -0.1042 / -0.0996\n",
            "[1][12/12][149/390]\tLoss_D: -0.0386\tLoss_G: 0.1055\tD(x): -0.0639\tD(G(z)): -0.1025 / -0.1055\n",
            "[2][12/12][159/390]\tLoss_D: -0.0319\tLoss_G: 0.0954\tD(x): -0.0727\tD(G(z)): -0.1046 / -0.0954\n",
            "[0][12/12][169/390]\tLoss_D: -0.0428\tLoss_G: 0.1025\tD(x): -0.0645\tD(G(z)): -0.1073 / -0.1025\n",
            "[1][12/12][179/390]\tLoss_D: -0.0371\tLoss_G: 0.1043\tD(x): -0.0641\tD(G(z)): -0.1012 / -0.1043\n",
            "[2][12/12][189/390]\tLoss_D: -0.0236\tLoss_G: 0.1060\tD(x): -0.0652\tD(G(z)): -0.0888 / -0.1060\n",
            "[0][12/12][199/390]\tLoss_D: -0.0411\tLoss_G: 0.1027\tD(x): -0.0629\tD(G(z)): -0.1040 / -0.1027\n",
            "[1][12/12][209/390]\tLoss_D: -0.0350\tLoss_G: 0.1016\tD(x): -0.0650\tD(G(z)): -0.1000 / -0.1016\n",
            "[2][12/12][219/390]\tLoss_D: -0.0295\tLoss_G: 0.0903\tD(x): -0.0768\tD(G(z)): -0.1063 / -0.0903\n",
            "[0][12/12][229/390]\tLoss_D: -0.0383\tLoss_G: 0.0994\tD(x): -0.0672\tD(G(z)): -0.1055 / -0.0994\n",
            "[1][12/12][239/390]\tLoss_D: -0.0416\tLoss_G: 0.1010\tD(x): -0.0644\tD(G(z)): -0.1060 / -0.1010\n",
            "[2][12/12][249/390]\tLoss_D: -0.0304\tLoss_G: 0.0933\tD(x): -0.0740\tD(G(z)): -0.1044 / -0.0933\n",
            "[0][12/12][259/390]\tLoss_D: -0.0391\tLoss_G: 0.0986\tD(x): -0.0641\tD(G(z)): -0.1031 / -0.0986\n",
            "[1][12/12][269/390]\tLoss_D: -0.0403\tLoss_G: 0.1017\tD(x): -0.0618\tD(G(z)): -0.1021 / -0.1017\n",
            "[2][12/12][279/390]\tLoss_D: -0.0259\tLoss_G: 0.1035\tD(x): -0.0657\tD(G(z)): -0.0916 / -0.1035\n",
            "[0][12/12][289/390]\tLoss_D: -0.0396\tLoss_G: 0.1043\tD(x): -0.0657\tD(G(z)): -0.1053 / -0.1043\n",
            "[1][12/12][299/390]\tLoss_D: -0.0401\tLoss_G: 0.0999\tD(x): -0.0635\tD(G(z)): -0.1036 / -0.0999\n",
            "[2][12/12][309/390]\tLoss_D: -0.0298\tLoss_G: 0.1004\tD(x): -0.0722\tD(G(z)): -0.1020 / -0.1004\n",
            "[0][12/12][319/390]\tLoss_D: -0.0397\tLoss_G: 0.1008\tD(x): -0.0635\tD(G(z)): -0.1033 / -0.1008\n",
            "[1][12/12][329/390]\tLoss_D: -0.0388\tLoss_G: 0.0987\tD(x): -0.0642\tD(G(z)): -0.1030 / -0.0987\n",
            "[2][12/12][339/390]\tLoss_D: -0.0301\tLoss_G: 0.1059\tD(x): -0.0667\tD(G(z)): -0.0968 / -0.1059\n",
            "[0][12/12][349/390]\tLoss_D: -0.0341\tLoss_G: 0.1055\tD(x): -0.0644\tD(G(z)): -0.0985 / -0.1055\n",
            "[1][12/12][359/390]\tLoss_D: -0.0375\tLoss_G: 0.1062\tD(x): -0.0634\tD(G(z)): -0.1009 / -0.1062\n",
            "[2][12/12][369/390]\tLoss_D: -0.0295\tLoss_G: 0.1019\tD(x): -0.0661\tD(G(z)): -0.0956 / -0.1019\n",
            "[0][12/12][379/390]\tLoss_D: -0.0388\tLoss_G: 0.0984\tD(x): -0.0662\tD(G(z)): -0.1050 / -0.0984\n",
            "[1][12/12][389/390]\tLoss_D: -0.0350\tLoss_G: 0.1053\tD(x): -0.0628\tD(G(z)): -0.0977 / -0.1053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYmn2_ZGcE1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses[display],label=\"G\")\n",
        "plt.plot(D_losses[display],label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lw-swUzuDcc",
        "colab_type": "code",
        "outputId": "cfb384d4-2f41-419d-e622-40a85a9ff925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#%%capture\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i ,(1,2,0)), animated=True)] for i in img_list[display]]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "display += 1\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2T3Om_WbSfBR",
        "outputId": "e2811c4e-cbba-4512-e09b-be4baafc7daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#%%capture\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i ,(1,2,0)), animated=True)] for i in img_list[display]]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "display += 1\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "git63Rgj9u8a",
        "colab_type": "code",
        "outputId": "956dc08d-8b5e-45d8-e326-619f6f08c805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(display)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}